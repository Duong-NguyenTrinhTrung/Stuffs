{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled1.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"SmVJlMOk_OOc","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":423},"outputId":"ad4ed08d-466e-40c8-951a-f8716da0e1f1","executionInfo":{"status":"ok","timestamp":1571823633846,"user_tz":-480,"elapsed":6792,"user":{"displayName":"Yang Ruan","photoUrl":"","userId":"15695464595501500414"}}},"source":["!pip install pytorch-pretrained-bert"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting pytorch-pretrained-bert\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n","\u001b[K     |████████████████████████████████| 133kB 2.8MB/s \n","\u001b[?25hRequirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.3.0+cu100)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2.21.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (4.28.1)\n","Collecting regex (from pytorch-pretrained-bert)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ff/60/d9782c56ceefa76033a00e1f84cd8c586c75e6e7fea2cd45ee8b46a386c5/regex-2019.08.19-cp36-cp36m-manylinux1_x86_64.whl (643kB)\n","\u001b[K     |████████████████████████████████| 645kB 8.9MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.16.5)\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.9.251)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2019.9.11)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2.8)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n","Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.2.1)\n","Requirement already satisfied: botocore<1.13.0,>=1.12.251 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (1.12.251)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.9.4)\n","Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.251->boto3->pytorch-pretrained-bert) (0.15.2)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.251->boto3->pytorch-pretrained-bert) (2.5.3)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\"->botocore<1.13.0,>=1.12.251->boto3->pytorch-pretrained-bert) (1.12.0)\n","Installing collected packages: regex, pytorch-pretrained-bert\n","Successfully installed pytorch-pretrained-bert-0.6.2 regex-2019.8.19\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"F1I9H3YT_UyX","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"e7e4a532-dc72-40d9-caff-bf7bca8605b0","executionInfo":{"status":"ok","timestamp":1571823645223,"user_tz":-480,"elapsed":5621,"user":{"displayName":"Yang Ruan","photoUrl":"","userId":"15695464595501500414"}}},"source":["import torch\n","from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n","\n","# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n","import logging\n","#logging.basicConfig(level=logging.INFO)\n","\n","import matplotlib.pyplot as plt\n","% matplotlib inline\n","\n","# Load pre-trained model tokenizer (vocabulary)\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["100%|██████████| 231508/231508 [00:00<00:00, 6287327.96B/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"vy4Zpyti_X_7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"404f26c2-2421-49c9-fab3-6959ffec82dc","executionInfo":{"status":"ok","timestamp":1571823652354,"user_tz":-480,"elapsed":656,"user":{"displayName":"Yang Ruan","photoUrl":"","userId":"15695464595501500414"}}},"source":["text = \"Here is the sentence I want embeddings for.\"\n","text = \"After stealing money from the bank vault, the bank robber was seen fishing on the Mississippi river bank.\"\n","marked_text = \"[CLS] \" + text + \" [SEP]\"\n","\n","print (marked_text)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["[CLS] After stealing money from the bank vault, the bank robber was seen fishing on the Mississippi river bank. [SEP]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Sp7ihJi4_awM","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":54},"outputId":"6f44138f-6e7e-45ef-a894-af67a89ebce1","executionInfo":{"status":"ok","timestamp":1571823663704,"user_tz":-480,"elapsed":645,"user":{"displayName":"Yang Ruan","photoUrl":"","userId":"15695464595501500414"}}},"source":["tokenized_text = tokenizer.tokenize(marked_text)\n","print (tokenized_text)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["['[CLS]', 'after', 'stealing', 'money', 'from', 'the', 'bank', 'vault', ',', 'the', 'bank', 'robber', 'was', 'seen', 'fishing', 'on', 'the', 'mississippi', 'river', 'bank', '.', '[SEP]']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XS1PK1p2_gGM","colab_type":"code","colab":{}},"source":["indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KdYGXl5o_jHc","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"40de375f-a2d6-4379-e03f-a49b1af496d1","executionInfo":{"status":"ok","timestamp":1571823697338,"user_tz":-480,"elapsed":644,"user":{"displayName":"Yang Ruan","photoUrl":"","userId":"15695464595501500414"}}},"source":["segments_ids = [1] * len(tokenized_text)\n","print (segments_ids)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RXWFpNY6_mUF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"604c4def-dd17-4d99-c269-b33ecbdb05cb","executionInfo":{"status":"ok","timestamp":1571823726851,"user_tz":-480,"elapsed":17200,"user":{"displayName":"Yang Ruan","photoUrl":"","userId":"15695464595501500414"}}},"source":["# Load pre-trained model (weights)\n","model = BertModel.from_pretrained('bert-base-uncased')\n","\n","# Put the model in \"evaluation\" mode, meaning feed-forward operation.\n","model.eval()"],"execution_count":7,"outputs":[{"output_type":"stream","text":["100%|██████████| 407873900/407873900 [00:07<00:00, 52671113.60B/s]\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["BertModel(\n","  (embeddings): BertEmbeddings(\n","    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n","    (position_embeddings): Embedding(512, 768)\n","    (token_type_embeddings): Embedding(2, 768)\n","    (LayerNorm): BertLayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (encoder): BertEncoder(\n","    (layer): ModuleList(\n","      (0): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (1): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (2): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (3): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (4): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (5): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (6): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (7): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (8): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (9): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (10): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","      (11): BertLayer(\n","        (attention): BertAttention(\n","          (self): BertSelfAttention(\n","            (query): Linear(in_features=768, out_features=768, bias=True)\n","            (key): Linear(in_features=768, out_features=768, bias=True)\n","            (value): Linear(in_features=768, out_features=768, bias=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (output): BertSelfOutput(\n","            (dense): Linear(in_features=768, out_features=768, bias=True)\n","            (LayerNorm): BertLayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (intermediate): BertIntermediate(\n","          (dense): Linear(in_features=768, out_features=3072, bias=True)\n","        )\n","        (output): BertOutput(\n","          (dense): Linear(in_features=3072, out_features=768, bias=True)\n","          (LayerNorm): BertLayerNorm()\n","          (dropout): Dropout(p=0.1, inplace=False)\n","        )\n","      )\n","    )\n","  )\n","  (pooler): BertPooler(\n","    (dense): Linear(in_features=768, out_features=768, bias=True)\n","    (activation): Tanh()\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"-NNedtcB_sET","colab_type":"code","colab":{}},"source":["# Convert inputs to PyTorch tensors\n","tokens_tensor = torch.tensor([indexed_tokens])\n","segments_tensors = torch.tensor([segments_ids])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GAGdQQuE_wfb","colab_type":"code","colab":{}},"source":["# Predict hidden states features for each layer\n","with torch.no_grad():\n","    encoded_layers, _ = model(tokens_tensor, segments_tensors)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AoeoSTm__zCs","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":84},"outputId":"dca40b86-14fa-433c-d630-75948198d6d3","executionInfo":{"status":"ok","timestamp":1571823762674,"user_tz":-480,"elapsed":648,"user":{"displayName":"Yang Ruan","photoUrl":"","userId":"15695464595501500414"}}},"source":["print (\"Number of layers:\", len(encoded_layers))\n","layer_i = 0\n","\n","print (\"Number of batches:\", len(encoded_layers[layer_i]))\n","batch_i = 0\n","\n","print (\"Number of tokens:\", len(encoded_layers[layer_i][batch_i]))\n","token_i = 0\n","\n","print (\"Number of hidden units:\", len(encoded_layers[layer_i][batch_i][token_i]))"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Number of layers: 12\n","Number of batches: 1\n","Number of tokens: 22\n","Number of hidden units: 768\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5iJNctcp_2RV","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":50},"outputId":"d0bd2091-53e4-4134-d82c-387757608891","executionInfo":{"status":"ok","timestamp":1571823776584,"user_tz":-480,"elapsed":652,"user":{"displayName":"Yang Ruan","photoUrl":"","userId":"15695464595501500414"}}},"source":["# Convert the hidden state embeddings into single token vectors\n","\n","# Holds the list of 12 layer embeddings for each token\n","# Will have the shape: [# tokens, # layers, # features]\n","token_embeddings = [] \n","\n","# For each token in the sentence...\n","for token_i in range(len(tokenized_text)):\n","  \n","  # Holds 12 layers of hidden states for each token \n","  hidden_layers = [] \n","  \n","  # For each of the 12 layers...\n","  for layer_i in range(len(encoded_layers)):\n","    \n","    # Lookup the vector for `token_i` in `layer_i`\n","    vec = encoded_layers[layer_i][batch_i][token_i]\n","    \n","    hidden_layers.append(vec)\n","    \n","  token_embeddings.append(hidden_layers)\n","\n","# Sanity check the dimensions:\n","print (\"Number of tokens in sequence:\", len(token_embeddings))\n","print (\"Number of layers per token:\", len(token_embeddings[0]))"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Number of tokens in sequence: 22\n","Number of layers per token: 12\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Y76wnHii_5Oe","colab_type":"code","colab":{}},"source":["#create word vector\n","concatenated_last_4_layers = [torch.cat((layer[-1], layer[-2], layer[-3], layer[-4]), 0) for layer in token_embeddings] # [number_of_tokens, 3072]\n","\n","summed_last_4_layers = [torch.sum(torch.stack(layer)[-4:], 0) for layer in token_embeddings] # [number_of_tokens, 768]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BFjAllvE_-oY","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":50},"outputId":"33e2bb47-a479-470f-dc29-108dbc3d9369","executionInfo":{"status":"ok","timestamp":1571824591761,"user_tz":-480,"elapsed":654,"user":{"displayName":"Yang Ruan","photoUrl":"","userId":"15695464595501500414"}}},"source":["#create sentence vector\n","sentence_embedding = torch.mean(encoded_layers[11], 1)\n","print (\"Our final sentence embedding vector of shape:\"), sentence_embedding[0].shape[0]"],"execution_count":23,"outputs":[{"output_type":"stream","text":["Our final sentence embedding vector of shape:\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["(None, 768)"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"id":"1l1VorzMDH9N","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":101},"outputId":"5a9487af-3216-4c6f-9f22-d33dd1fd9e38","executionInfo":{"status":"ok","timestamp":1571824651074,"user_tz":-480,"elapsed":644,"user":{"displayName":"Yang Ruan","photoUrl":"","userId":"15695464595501500414"}}},"source":["print (\"Our final sentence embedding vector of shape:\"), sentence_embedding[0][:20]"],"execution_count":25,"outputs":[{"output_type":"stream","text":["Our final sentence embedding vector of shape:\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["(None,\n"," tensor([ 0.0329, -0.2346, -0.0799,  0.3891,  0.8879,  0.2137, -0.0078,  0.6269,\n","         -0.0326, -0.3470,  0.1233, -0.0948, -0.0744,  0.4552, -0.4722,  0.1034,\n","          0.3467,  0.1041,  0.5437,  0.0691]))"]},"metadata":{"tags":[]},"execution_count":25}]}]}