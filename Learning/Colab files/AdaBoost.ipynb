{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"AdaBoost.ipynb","provenance":[],"authorship_tag":"ABX9TyO4ulJdj9MImnFh3nF/VMOw"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"9hCAADGfoI16","executionInfo":{"status":"ok","timestamp":1613969035815,"user_tz":-480,"elapsed":647,"user":{"displayName":"Yang Ruan","photoUrl":"","userId":"15695464595501500414"}}},"source":["import os\r\n","# Importing the libraries\r\n","import numpy as np\r\n","import pandas as pd\r\n","import math\r\n","from sklearn.svm import SVC\r\n","from sklearn.metrics import confusion_matrix, roc_auc_score\r\n","from sklearn.metrics import roc_curve, auc, precision_recall_curve\r\n","from matplotlib import pyplot\r\n","from sklearn.ensemble import AdaBoostClassifier\r\n","from sklearn.datasets import make_classification"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"giBL8pDcob-V","executionInfo":{"status":"ok","timestamp":1613969036043,"user_tz":-480,"elapsed":865,"user":{"displayName":"Yang Ruan","photoUrl":"","userId":"15695464595501500414"}}},"source":["def labelToOneHot(label):# 0 --> [1 0], 1--> [0 1]\r\n","    label = label.reshape(len(label), 1)\r\n","    label = np.append(label, label, axis = 1)\r\n","    label[:,0] = label[:,0] == 0;\r\n","    return label"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"1Zhq6Ou3ofSC","executionInfo":{"status":"ok","timestamp":1613969036413,"user_tz":-480,"elapsed":1229,"user":{"displayName":"Yang Ruan","photoUrl":"","userId":"15695464595501500414"}}},"source":["def classificationPerformanceByThreshold(threshold, y_pred, y_test):\r\n","    \"\"\"\r\n","    # Making the Confusion Matrix\r\n","    cm = confusion_matrix(y_test, Y_pred)\r\n","    print(\"some y_pred \",Y_pred[:5])\r\n","    tn, fp, fn, tp = cm.ravel()\r\n","    \"\"\"\r\n","    y_test = labelToOneHot(y_test)\r\n","    auc=roc_auc_score(y_test, y_pred)\r\n","    y_test = np.argmax(y_test, axis = 1)\r\n","    \r\n","    \r\n","    Y_pred = np.empty_like(y_pred)\r\n","    for i in range(len(y_pred)):\r\n","        if y_pred[i][0]>=threshold:\r\n","            Y_pred[i]=np.array([1,0]) #assign as class pos\r\n","        else:\r\n","            Y_pred[i]=np.array([0,1]) #assign as class neg\r\n","    \r\n","    Y_pred = np.argmax(Y_pred, axis = 1)\r\n","    \r\n","    \r\n","    cm = confusion_matrix(y_test, Y_pred, labels = [0,1])\r\n","   \r\n","    tn=cm[0][0]\r\n","    fn=cm[1][0]\r\n","    tp=cm[1][1]\r\n","    fp=cm[0][1]\r\n","    \r\n","    if float(tp)+float(fn)==0:\r\n","        TPR=round(float(tp)/0.00000001,3)\r\n","    else:\r\n","        TPR=round(float(tp)/(float(tp)+float(fn)),3)\r\n","    \r\n","    if float(fp)+float(tn)==0:\r\n","        FPR=round(float(fp)/(0.00000001),3)\r\n","    else:\r\n","        FPR=round(float(fp)/(float(fp)+float(tn)),3)\r\n","    \r\n","    if float(tp) + float(fp) + float(fn) + float(tn)==0:\r\n","        accuracy = round((float(tp) + float(tn))/(0.00000001),3)    \r\n","    else:\r\n","        accuracy = round((float(tp) + float(tn))/(float(tp) + float(fp) + float(fn) + float(tn)),3)\r\n","        \r\n","    if float(tn) + float(fp)==0:\r\n","        specitivity=round(float(tn)/(0.00000001),3)\r\n","    else:\r\n","        specitivity=round(float(tn)/(float(tn) + float(fp)),3)\r\n","        \r\n","    if float(tp) + float(fn)==0:\r\n","        sensitivity = round(float(tp)/(0.00000001),3)\r\n","    else:\r\n","        sensitivity = round(float(tp)/(float(tp) + float(fn)),3)\r\n","    \r\n","    if float(tp) + float(fp)==0:\r\n","        precision = round(float(tp)/(0.00000001),3)\r\n","    else:\r\n","        precision = round(float(tp)/(float(tp) + float(fp)),3)\r\n","    \r\n","    if math.sqrt((float(tp)+float(fp))*(float(tp)+float(fn))*(float(tn)+float(fp))*(float(tn)+float(fn)))==0:\r\n","        mcc = round((float(tp)*float(tn) - float(fp)*float(fn))/0.00000001,3)\r\n","    else:\r\n","        mcc = round((float(tp)*float(tn) - float(fp)*float(fn))/math.sqrt(\r\n","                                                                    (float(tp)+float(fp))\r\n","                                                                    *(float(tp)+float(fn))\r\n","                                                                    *(float(tn)+float(fp))\r\n","                                                                    *(float(tn)+float(fn))\r\n","                                                                    ),3)\r\n","    balAcc=(sensitivity+specitivity)/2\r\n","    if (sensitivity+precision)==0:\r\n","        f_measure = round(2*sensitivity*precision/(0.00000001),3)\r\n","    else:\r\n","        f_measure = round(2*sensitivity*precision/(sensitivity+precision),3)\r\n","    \r\n","    return accuracy, specitivity, sensitivity, mcc, tp, tn, fp, fn, TPR, FPR, balAcc, precision, f_measure, auc"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"2xserFEeonR6","executionInfo":{"status":"ok","timestamp":1613969036414,"user_tz":-480,"elapsed":1225,"user":{"displayName":"Yang Ruan","photoUrl":"","userId":"15695464595501500414"}}},"source":["def runForY_pred(c,g,train_file, test_file):\r\n","    # Importing the dataset\r\n","    print(\"Start AdaBoost runForY_pred\")\r\n","    print(train_file,\" is processing\")\r\n","    dataset = pd.read_csv(train_file, header=None)\r\n","    X_train = dataset.iloc[:, 0:-1].values\r\n","    y_train = dataset.iloc[:, -1].values\r\n","    print(\"\\nTraining file X shape \",X_train.shape,\" Y shape \",y_train.shape)\r\n","    \r\n","    \r\n","    print(test_file,\" is processing\")\r\n","    dataset = pd.read_csv(test_file, header=None)\r\n","    X_test = dataset.iloc[:, 0:-1].values\r\n","    y_test = dataset.iloc[:, -1].values\r\n","    print(\"\\nTesting file X shape \",X_test.shape,\" Y shape \",y_test.shape)\r\n","    \r\n","\r\n","    # Fitting Kernel SVM to the Training set\r\n","    classifier = SVC(C=c, gamma=g, kernel = 'rbf', random_state = 0, probability=True)\r\n","    classifier.fit(X_train, y_train)\r\n","    print(\" model.classes_ \",classifier.classes_)\r\n","    # joblib.dump(classifier, cla+'.pickle_model.pkl', protocol=2)\r\n","\r\n","    # Predicting the Test set results\r\n","    y_pred = classifier.predict_proba(X_test)\r\n","    y_hat = classifier.predict(X_test)\r\n","    \r\n","    print(\"Finish SVM runForY_pred\")\r\n","    \r\n","    return y_test, y_hat, y_pred"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"wr0wbG9AoqsE","executionInfo":{"status":"ok","timestamp":1613969036415,"user_tz":-480,"elapsed":1222,"user":{"displayName":"Yang Ruan","photoUrl":"","userId":"15695464595501500414"}}},"source":["def run(c,g,train_file, test_file,result_file):\r\n","    # Importing the dataset\r\n","    print(train_file,\" is processing\")\r\n","    dataset = pd.read_csv(train_file, header=None)\r\n","    X_train = dataset.iloc[:, 0:-1].values\r\n","    y_train = dataset.iloc[:, -1].values\r\n","    print(\"\\nTraining file X shape \",X_train.shape,\" Y shape \",y_train.shape)\r\n","    \r\n","    \r\n","    print(test_file,\" is processing\")\r\n","    dataset = pd.read_csv(test_file, header=None)\r\n","    X_test = dataset.iloc[:, 0:-1].values\r\n","    y_test = dataset.iloc[:, -1].values\r\n","    print(\"\\nTesting file X shape \",X_test.shape,\" Y shape \",y_test.shape)\r\n","    \r\n","\r\n","    # Fitting Kernel SVM to the Training set\r\n","    classifier = SVC(C=c, gamma=g, kernel = 'rbf', random_state = 0, probability=True)\r\n","    classifier.fit(X_train, y_train)\r\n","    print(\" model.classes_ \",classifier.classes_)\r\n","    # joblib.dump(classifier, cla+'.pickle_model.pkl', protocol=2)\r\n","\r\n","    # Predicting the Test set results\r\n","    y_pred = classifier.predict_proba(X_test)\r\n","    \r\n","    \r\n","    f2=open(result_file,\"a\")\r\n","    f2.write(\"Threshold ,Aaccuracy ,Specitivity ,Sensitivity ,MCC ,Precision ,tp ,tn ,fp ,fn ,TPR ,FPR ,balAcc ,precision , f_measure ,AUC\\n\")\r\n","    threshold=0.01\r\n","    while threshold<1.01:\r\n","        accuracy, specitivity, sensitivity, mcc, tp, tn, fp, fn, TPR, FPR, balAcc, precision, f_measure, auc = classificationPerformanceByThreshold(threshold, y_pred, y_test)\r\n","        f2.write(str(threshold)+\", \"+str(accuracy)+\", \"+str(specitivity)+\", \"+str(sensitivity)+\", \"+str(mcc)+\", \"+str(precision)+\", \"+str(tp)+\", \"+str(tn)+\", \"+str(fp)+\", \"+str(fn)+\", \"+str(TPR)+\", \"+str(FPR)+\", \"+str(balAcc)+\", \"+str(precision)+\", \"+str(f_measure)+\", \"+str(auc)+\"\\n\")\r\n","        threshold+=0.002\r\n","    f2.close()"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_4SPM4j3o0V8","executionInfo":{"status":"ok","timestamp":1613969036415,"user_tz":-480,"elapsed":1217,"user":{"displayName":"Yang Ruan","photoUrl":"","userId":"15695464595501500414"}},"outputId":"2446d289-96ba-401f-cc6d-feb5859ae057"},"source":["from google.colab import drive\r\n","drive.mount('/content/drive')"],"execution_count":15,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-GhvRlgXov5r","executionInfo":{"status":"ok","timestamp":1613969036416,"user_tz":-480,"elapsed":1210,"user":{"displayName":"Yang Ruan","photoUrl":"","userId":"15695464595501500414"}},"outputId":"86dad79d-b429-4776-93f5-87effc76f2a3"},"source":["!ls \"drive/MyDrive/Electron transport - AutoEncoder/FMN/pssm features wd 15\""],"execution_count":16,"outputs":[{"output_type":"stream","text":[" 0_es500.maxft20.AUPR.png    3_es500.maxft20.AUROC.png\t input.fold.test2.csv\n"," 0_es500.maxft20.AUROC.png   3_g0.001.c0.1.AUPR.png\t input.fold.test3.csv\n"," 0_g0.001.c0.1.AUPR.png      3_g0.001.c0.1.AUROC.png\t input.fold.test4.csv\n"," 0_g0.001.c0.1.AUROC.png     4_es500.maxft20.AUPR.png\t input.fold.test5.csv\n"," 1_es500.maxft20.AUPR.png    4_es500.maxft20.AUROC.png\t input.fold.train1.csv\n"," 1_es500.maxft20.AUROC.png   4_g0.001.c0.1.AUPR.png\t input.fold.train2.csv\n"," 1_g0.001.c0.1.AUPR.png      4_g0.001.c0.1.AUROC.png\t input.fold.train3.csv\n"," 1_g0.001.c0.1.AUROC.png     5_es500.maxft20.AUPR.png\t input.fold.train4.csv\n"," 2_es500.maxft20.AUPR.png    5_es500.maxft20.AUROC.png\t input.fold.train5.csv\n"," 2_es500.maxft20.AUROC.png   5_g0.001.c0.1.AUPR.png\t input.train.csv\n"," 2_g0.001.c0.1.AUPR.png      5_g0.001.c0.1.AUROC.png\t'SVM results'\n"," 2_g0.001.c0.1.AUROC.png     ind.test.csv\n"," 3_es500.maxft20.AUPR.png    input.fold.test1.csv\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9jDr0oIeo_gc","executionInfo":{"status":"ok","timestamp":1613969254638,"user_tz":-480,"elapsed":583,"user":{"displayName":"Yang Ruan","photoUrl":"","userId":"15695464595501500414"}}},"source":["def runAndPlot(n_estimators,learning_rate,train_file, test_file,fold):\r\n","    # Importing the dataset\r\n","    print(\"Start AdaBoost runForY_pred\")\r\n","    print(train_file,\" is processing\")\r\n","    dataset = pd.read_csv(train_file, header=None)\r\n","    X_train = dataset.iloc[:, 0:-1].values\r\n","    y_train = dataset.iloc[:, -1].values\r\n","    print(\"\\nTraining file X shape \",X_train.shape,\" Y shape \",y_train.shape)\r\n","    \r\n","    \r\n","    print(test_file,\" is processing\")\r\n","    dataset = pd.read_csv(test_file, header=None)\r\n","    X_test = dataset.iloc[:, 0:-1].values\r\n","    y_test = dataset.iloc[:, -1].values\r\n","    y_test=labelToOneHot(y_test)\r\n","    print(\"\\nTesting file X shape \",X_test.shape,\" Y shape \",y_test.shape)\r\n","    \r\n","\r\n","    # Fitting Kernel SVM to the Training set\r\n","    classifier = AdaBoostClassifier(n_estimators=n_estimators, learning_rate=learning_rate, random_state=0)\r\n","    classifier.fit(X_train, y_train)\r\n","    print(\" model.classes_ \",classifier.classes_)\r\n","    # joblib.dump(classifier, cla+'.pickle_model.pkl', protocol=2)\r\n","\r\n","    # Predicting the Test set results\r\n","    y_pred = classifier.predict_proba(X_test)\r\n","    y_hat = classifier.predict(X_test)\r\n","    \r\n","    # calculate roc curves\r\n","    fpr, tpr, _ = roc_curve(y_test[:,1], y_pred[:,1])\r\n","    # plot the roc curve for the model\r\n","    roc_auc = roc_auc_score(y_test, y_pred)\r\n","    pyplot.plot(fpr, tpr, marker='.', label=\"AdaBoost-AU ROC is {0:.3f}%\".format(roc_auc) )\r\n","    # axis labels\r\n","    pyplot.xlabel('False Positive Rate')\r\n","    pyplot.ylabel('True Positive Rate')\r\n","    # show the legend\r\n","    pyplot.legend()\r\n","    pyplot.title(str(fold)+\"_es\"+str(es)+\".lr\"+str(lr))\r\n","    #save the plot\r\n","    folderForImage=\"drive/MyDrive/Electron transport - AutoEncoder/FMN/pssm features wd 15\"\r\n","    pyplot.savefig(folderForImage+\"/AdaBoost.\"+str(fold)+\"_es\"+str(es)+\".lr\"+str(lr)+\".AUROC.png\")\r\n","    # show the plot\r\n","    pyplot.show()\r\n","\r\n","    # calculate PR roc curve for model\r\n","    # precisions, recalls, thresholds  = precision_recall_curve(y_test, pos_probs)\r\n","    precisions, recalls, thresholds  = precision_recall_curve(y_test[:,1], y_pred[:,1])\r\n","    # calculate the precision-recall auc\r\n","    auc_score = auc(recalls, precisions)\r\n","    #plot\r\n","    pyplot.plot(recalls, precisions, marker='.', label=\"AdaBoost-AUPR curve is {0:.3f}%\".format(auc_score))\r\n","    # axis labels\r\n","    pyplot.xlabel('Recall')\r\n","    pyplot.ylabel('Precision')\r\n","    # show the legend\r\n","    pyplot.legend()\r\n","    pyplot.title(str(fold)+\"_es\"+str(es)+\".lr\"+str(lr))\r\n","    #save to image\r\n","    pyplot.savefig(folderForImage+\"/AdaBoost.\"+str(fold)+\"_es\"+str(es)+\".lr\"+str(lr)+\".AUPR.png\")\r\n","    # show the plot\r\n","    pyplot.show()\r\n","\r\n"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1Edf02rS6KyxcaxC837le5-ty0y5Sp52K"},"id":"ArBYt7D2qbXT","executionInfo":{"status":"ok","timestamp":1613972398736,"user_tz":-480,"elapsed":3135365,"user":{"displayName":"Yang Ruan","photoUrl":"","userId":"15695464595501500414"}},"outputId":"35fb22c7-a5d4-488c-94e8-7cfe2dcf97d7"},"source":["bindingTypes=[\"FMN\"]\r\n","wd=15\r\n","for bdType in bindingTypes:\r\n","  path3=\"drive/MyDrive/Electron transport - AutoEncoder/FMN/pssm features wd 15\"\r\n","  for es in [500,1000,2000]:\r\n","    for lr in [1,0.1, 0.01, 0.001]:\r\n","      runAndPlot(es,lr,path3+\"/input.train.csv\", path3+\"/ind.test.csv\",0)\r\n","      for fold in [1,2,3,4,5]:\r\n","        runAndPlot(es,lr,path3+\"/input.fold.train\"+str(fold)+\".csv\", path3+\"/input.fold.test\"+str(fold)+\".csv\", fold)\r\n","  "],"execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]}]}