{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"LEARNING WORD EMBEDDINGS WITH THE EMBEDDING LAYER.ipynb","provenance":[],"authorship_tag":"ABX9TyOrMo+Rnqv6Ffer5+HAXy0+"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"a729YYkg_TpE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"e3b6317a-dc0d-4140-dcf5-9fbc34a4d8e5","executionInfo":{"status":"ok","timestamp":1588399564327,"user_tz":-480,"elapsed":2422,"user":{"displayName":"Yang Ruan","photoUrl":"","userId":"15695464595501500414"}}},"source":["from keras.layers import Embedding"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"ACuPH8sp_aVe","colab_type":"code","colab":{}},"source":["embedding_layer = Embedding(1000, 64)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ry9vV45h_xyi","colab_type":"code","colab":{}},"source":["from keras.datasets import imdb\n","from keras import preprocessing"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rInEZEv2_3U5","colab_type":"code","colab":{}},"source":["max_features = 10000\n","maxlen = 20"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6RV3ZkB9_6fJ","colab_type":"code","colab":{}},"source":["(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vGyjk4MsAGrA","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":156},"outputId":"9100a6d0-c0b1-43d5-ff2e-13cd3c1d54eb","executionInfo":{"status":"ok","timestamp":1588405171229,"user_tz":-480,"elapsed":554,"user":{"displayName":"Yang Ruan","photoUrl":"","userId":"15695464595501500414"}}},"source":["print(x_train.shape)\n","print(y_train.shape)\n","print(x_test.shape)\n","print(y_test.shape)\n","\n","print(type(x_train))\n","print(type(y_train))\n","print(type(x_test))\n","print(type(y_test))"],"execution_count":43,"outputs":[{"output_type":"stream","text":["(25000,)\n","(25000,)\n","(25000,)\n","(25000,)\n","<class 'numpy.ndarray'>\n","<class 'numpy.ndarray'>\n","<class 'numpy.ndarray'>\n","<class 'numpy.ndarray'>\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VQ0upYQwBekd","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":107},"outputId":"984e20b9-6cd6-4ebb-cf88-67733ff9d618","executionInfo":{"status":"ok","timestamp":1588405174968,"user_tz":-480,"elapsed":581,"user":{"displayName":"Yang Ruan","photoUrl":"","userId":"15695464595501500414"}}},"source":["print(x_train[0:3])\n","print(y_train[0:3])"],"execution_count":44,"outputs":[{"output_type":"stream","text":["[list([1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32])\n"," list([1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 2, 4, 1153, 9, 194, 775, 7, 8255, 2, 349, 2637, 148, 605, 2, 8003, 15, 123, 125, 68, 2, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 2, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 2, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 2, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95])\n"," list([1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 5974, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2401, 311, 12, 16, 3711, 33, 75, 43, 1829, 296, 4, 86, 320, 35, 534, 19, 263, 4821, 1301, 4, 1873, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 1716, 43, 645, 662, 8, 257, 85, 1200, 42, 1228, 2578, 83, 68, 3912, 15, 36, 165, 1539, 278, 36, 69, 2, 780, 8, 106, 14, 6905, 1338, 18, 6, 22, 12, 215, 28, 610, 40, 6, 87, 326, 23, 2300, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2307, 51, 9, 170, 23, 595, 116, 595, 1352, 13, 191, 79, 638, 89, 2, 14, 9, 8, 106, 607, 624, 35, 534, 6, 227, 7, 129, 113])]\n","[1 0 0]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YiJLkPfHAszn","colab_type":"code","colab":{}},"source":["x_train = preprocessing.sequence.pad_sequences(x_train, maxlen=maxlen)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GyVLUSpEAyen","colab_type":"code","colab":{}},"source":["x_test = preprocessing.sequence.pad_sequences(x_test, maxlen=maxlen)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YWQhO2ljBWng","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":173},"outputId":"031a3555-69b1-435d-94a1-52d4ac6937a4","executionInfo":{"status":"ok","timestamp":1588405182237,"user_tz":-480,"elapsed":602,"user":{"displayName":"Yang Ruan","photoUrl":"","userId":"15695464595501500414"}}},"source":["print(x_train.shape)\n","print(x_test.shape)\n","print(x_train[0:3])\n","print(y_train[0:3])"],"execution_count":47,"outputs":[{"output_type":"stream","text":["(25000, 20)\n","(25000, 20)\n","[[  65   16   38 1334   88   12   16  283    5   16 4472  113  103   32\n","    15   16 5345   19  178   32]\n"," [  23    4 1690   15   16    4 1355    5   28    6   52  154  462   33\n","    89   78  285   16  145   95]\n"," [1352   13  191   79  638   89    2   14    9    8  106  607  624   35\n","   534    6  227    7  129  113]]\n","[1 0 0]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"T-RAHJibCI-G","colab_type":"code","colab":{}},"source":["#Using an Embedding layer and classifier on the IMDB data\n","from keras.models import Sequential\n","from keras.layers import Flatten, Dense"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QGUtBzZzR8lI","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":260},"outputId":"d95f2c89-6bb2-4127-f986-b2191ef0c6a5","executionInfo":{"status":"ok","timestamp":1588405224590,"user_tz":-480,"elapsed":716,"user":{"displayName":"Yang Ruan","photoUrl":"","userId":"15695464595501500414"}}},"source":["model = Sequential()\n","#Specifies the maximum input length to the Embedding layer so you can later flatten the embedded inputs. After the Embedding layer,\n","#the activations have shape (samples, maxlen, 8)\n","model.add(Embedding(10000, 8, input_length=maxlen))\n","model.add(Flatten())\n","model.add(Dense(1, activation='sigmoid'))\n","model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n","model.summary()"],"execution_count":51,"outputs":[{"output_type":"stream","text":["Model: \"sequential_3\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_4 (Embedding)      (None, 20, 8)             80000     \n","_________________________________________________________________\n","flatten_3 (Flatten)          (None, 160)               0         \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 1)                 161       \n","=================================================================\n","Total params: 80,161\n","Trainable params: 80,161\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"59x4HHe1SiVe","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":956},"outputId":"9995693a-5683-484f-fc18-92b12fd62dd0","executionInfo":{"status":"ok","timestamp":1588405267405,"user_tz":-480,"elapsed":32627,"user":{"displayName":"Yang Ruan","photoUrl":"","userId":"15695464595501500414"}}},"source":["history = model.fit(x_train, y_train,epochs=25,batch_size=32,validation_split=0.2)"],"execution_count":52,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"],"name":"stderr"},{"output_type":"stream","text":["Train on 20000 samples, validate on 5000 samples\n","Epoch 1/25\n","20000/20000 [==============================] - 1s 68us/step - loss: 0.6763 - acc: 0.6018 - val_loss: 0.6356 - val_acc: 0.6838\n","Epoch 2/25\n","20000/20000 [==============================] - 1s 63us/step - loss: 0.5571 - acc: 0.7469 - val_loss: 0.5330 - val_acc: 0.7264\n","Epoch 3/25\n","20000/20000 [==============================] - 1s 64us/step - loss: 0.4675 - acc: 0.7861 - val_loss: 0.5033 - val_acc: 0.7398\n","Epoch 4/25\n","20000/20000 [==============================] - 1s 63us/step - loss: 0.4246 - acc: 0.8089 - val_loss: 0.4973 - val_acc: 0.7508\n","Epoch 5/25\n","20000/20000 [==============================] - 1s 63us/step - loss: 0.3954 - acc: 0.8243 - val_loss: 0.4963 - val_acc: 0.7544\n","Epoch 6/25\n","20000/20000 [==============================] - 1s 63us/step - loss: 0.3707 - acc: 0.8370 - val_loss: 0.5000 - val_acc: 0.7544\n","Epoch 7/25\n","20000/20000 [==============================] - 1s 62us/step - loss: 0.3489 - acc: 0.8511 - val_loss: 0.5057 - val_acc: 0.7542\n","Epoch 8/25\n","20000/20000 [==============================] - 1s 62us/step - loss: 0.3284 - acc: 0.8612 - val_loss: 0.5115 - val_acc: 0.7500\n","Epoch 9/25\n","20000/20000 [==============================] - 1s 61us/step - loss: 0.3098 - acc: 0.8712 - val_loss: 0.5191 - val_acc: 0.7526\n","Epoch 10/25\n","20000/20000 [==============================] - 1s 62us/step - loss: 0.2915 - acc: 0.8812 - val_loss: 0.5284 - val_acc: 0.7486\n","Epoch 11/25\n","20000/20000 [==============================] - 1s 63us/step - loss: 0.2751 - acc: 0.8896 - val_loss: 0.5375 - val_acc: 0.7468\n","Epoch 12/25\n","20000/20000 [==============================] - 1s 64us/step - loss: 0.2589 - acc: 0.8981 - val_loss: 0.5480 - val_acc: 0.7460\n","Epoch 13/25\n","20000/20000 [==============================] - 1s 64us/step - loss: 0.2439 - acc: 0.9056 - val_loss: 0.5603 - val_acc: 0.7400\n","Epoch 14/25\n","20000/20000 [==============================] - 1s 62us/step - loss: 0.2299 - acc: 0.9120 - val_loss: 0.5726 - val_acc: 0.7366\n","Epoch 15/25\n","20000/20000 [==============================] - 1s 63us/step - loss: 0.2167 - acc: 0.9171 - val_loss: 0.5851 - val_acc: 0.7350\n","Epoch 16/25\n","20000/20000 [==============================] - 1s 63us/step - loss: 0.2042 - acc: 0.9236 - val_loss: 0.5992 - val_acc: 0.7326\n","Epoch 17/25\n","20000/20000 [==============================] - 1s 63us/step - loss: 0.1928 - acc: 0.9290 - val_loss: 0.6129 - val_acc: 0.7324\n","Epoch 18/25\n","20000/20000 [==============================] - 1s 63us/step - loss: 0.1819 - acc: 0.9341 - val_loss: 0.6255 - val_acc: 0.7276\n","Epoch 19/25\n","20000/20000 [==============================] - 1s 63us/step - loss: 0.1719 - acc: 0.9374 - val_loss: 0.6403 - val_acc: 0.7282\n","Epoch 20/25\n","20000/20000 [==============================] - 1s 64us/step - loss: 0.1623 - acc: 0.9414 - val_loss: 0.6572 - val_acc: 0.7276\n","Epoch 21/25\n","20000/20000 [==============================] - 1s 64us/step - loss: 0.1536 - acc: 0.9460 - val_loss: 0.6704 - val_acc: 0.7218\n","Epoch 22/25\n","20000/20000 [==============================] - 1s 64us/step - loss: 0.1455 - acc: 0.9492 - val_loss: 0.6864 - val_acc: 0.7210\n","Epoch 23/25\n","20000/20000 [==============================] - 1s 64us/step - loss: 0.1377 - acc: 0.9528 - val_loss: 0.7030 - val_acc: 0.7202\n","Epoch 24/25\n","20000/20000 [==============================] - 1s 64us/step - loss: 0.1308 - acc: 0.9553 - val_loss: 0.7207 - val_acc: 0.7178\n","Epoch 25/25\n","20000/20000 [==============================] - 1s 64us/step - loss: 0.1237 - acc: 0.9578 - val_loss: 0.7380 - val_acc: 0.7152\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"hPKaDQyNSL4W","colab_type":"text"},"source":[""]}]}